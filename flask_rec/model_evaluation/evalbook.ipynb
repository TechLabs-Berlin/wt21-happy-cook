{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f83a32ed",
   "metadata": {},
   "source": [
    "# Template for Model Evaluation\n",
    "\n",
    "evaluation written by:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d8ecdb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "import advertools as adv\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import func_similarityfunc as sim\n",
    "import func_tfidf as tfidf\n",
    "import func_datapreprocessing as pp\n",
    "import func_predict as pred \n",
    "import func_eval as eve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c3cffcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rd_recipe = pd.read_csv('clean_recipe_data.csv')\n",
    "eval_recipe = pd.read_csv('model_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfe6594",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []    #processed text of the whole dataset\n",
    "for text in rd_recipe['cooking_directions']:\n",
    "    processed_text.append(word_tokenize(pp.preprocess(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b129d67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "[D, DF, N] = tfidf.vectorize_corpus(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe80f4",
   "metadata": {},
   "source": [
    "# Evaluation of Model 1:\n",
    "Details of Model 1: \n",
    "- The model vectorizes the 'cooking directions' text to represent the vector of the recipe\n",
    "- cosine similarity function was used "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da1aeb23",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_query = \"chicken, soy sauce\" # try a variety of queries yourself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a0a6da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "[ model , model_score] = pred.cosine_similarity(7, user_query, D , DF, N)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f116cad",
   "metadata": {},
   "source": [
    "The first evaluation metric "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e88a8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "eve.effectivity_eval(model, user_query,rd_recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6104df14",
   "metadata": {},
   "source": [
    "The second evaluation metric tries 4 model queries on a model dataset. The dataset consists of 57 data points. Each recipe was labeled either 1 or 0 to indicate whether it is a relevant recipe to the model query. The precision and recall scores are calculated for the top 7 recipes of each results.\n",
    "\n",
    "\n",
    "### Query List:\n",
    "\n",
    "Query 1:  beef, salt, pepper   \n",
    "\n",
    "Query 2: chicken, cream      \n",
    "\n",
    "Query 3: noodles, chicken   \n",
    "\n",
    "Query 4: beef, potatoes      \n",
    "\n",
    "### Score metric:\n",
    "1 = fulfils query\n",
    "\n",
    "0.5 = fulfils query but was not the user's preference\n",
    "\n",
    "0 = does not fulfil query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a88116",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_recipe.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9e8bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "[prec, rec] = eve.PrecRec_eval(eval_recipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d55107cf",
   "metadata": {},
   "source": [
    "# Evaluation of Model 2\n",
    "\n",
    "Use Jayashree's model version. add more details yourself. Analyze and compare the performance of each model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c571230",
   "metadata": {},
   "source": [
    "# Evaluation of Model 3\n",
    "\n",
    "Use Bilal's model version. add more details yourself. Analyze and compare the performance of each model!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c7ab13",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
